{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "import cv2\n",
    "import csv\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import mediapipe as mp \n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1724517650.344616 8728518 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88.1), renderer: Apple M1 Pro\n"
     ]
    }
   ],
   "source": [
    "# Hand detection model initialization\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "hands = mp_hands.Hands(\n",
    "    max_num_hands = 2,\n",
    "    min_detection_confidence = 0.7,\n",
    "    min_tracking_confidence = 0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1724517650.360419 9431513 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1724517650.373418 9431509 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    }
   ],
   "source": [
    "def calc_bounding_box(image, landmarks):\n",
    "    image_width, image_height = image.shape[1], image.shape[0]\n",
    "\n",
    "    landmark_array = np.empty((0,2), int)\n",
    "\n",
    "    for _, landmark in enumerate(landmarks.landmark):\n",
    "        landmark_x = min(int(landmark.x * image_width), image_width - 1)\n",
    "        landmark_y = min(int(landmark.y * image_height), image_height - 1)\n",
    "        landmark_point = [np.array((landmark_x, landmark_y))]\n",
    "\n",
    "        landmark_array = np.append(landmark_array, landmark_point, axis = 0)\n",
    "\n",
    "    x,y,w,h = cv2.boundingRect(landmark_array)\n",
    "    return [x,y,x+w,y+h]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def censor_function(image, brect):\n",
    "    roi = image[brect[1]:brect[3], brect[0]:brect[2]]\n",
    "    blur_image = cv2.GaussianBlur(roi,(151,151),0)\n",
    "    \n",
    "    image[brect[1]:brect[3], brect[0]:brect[2]] = blur_image\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bounding_box(image, brect, sign, handedness):\n",
    "    cv2.rectangle(image,(brect[0], brect[1]), (brect[2], brect[3]), (0,0,0), 1)\n",
    "\n",
    "    info_text = handedness.classification[0].label[0:]    \n",
    "    if sign!= \"\":\n",
    "        info_text = info_text + \":\" + sign\n",
    "    cv2.putText(image, info_text, (brect[0] + 5, brect[1] - 4), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 1, cv2.LINE_AA)\n",
    "\n",
    "    if sign == \"Fuck\":\n",
    "        image = censor_function(image, brect)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_landmark_points(image, landmarks):\n",
    "    image_width, image_height = image.shape[1], image.shape[0]\n",
    "\n",
    "    landmark_points = []\n",
    "\n",
    "    for _, landmark in enumerate(landmarks.landmark):\n",
    "        landmark_x = min(int(landmark.x * image_width), image_width - 1)\n",
    "        landmark_y = min(int(landmark.y * image_height), image_height - 1)\n",
    "\n",
    "        landmark_points.append([landmark_x, landmark_y])\n",
    "    \n",
    "    return landmark_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_landmark_points(image, landmark_points):\n",
    "    if len(landmark_points) > 0:\n",
    "        for index, landmark in enumerate(landmark_points):\n",
    "            if index == 0:\n",
    "                cv2.circle(image,(landmark[0],landmark[1]), 5, (0,255,255), -11)\n",
    "            if index == 1:\n",
    "                cv2.circle(image,(landmark[0],landmark[1]), 5, (0,255,255), -1)\n",
    "                \n",
    "            if index == 2:\n",
    "                cv2.circle(image,(landmark[0],landmark[1]), 5, (0,255,255), -1)\n",
    "                \n",
    "            if index == 3:\n",
    "                cv2.circle(image,(landmark[0],landmark[1]), 5, (0,255,255), -1)\n",
    "                \n",
    "            if index == 4:\n",
    "                cv2.circle(image,(landmark[0],landmark[1]), 5, (0,255,255), -1)\n",
    "                \n",
    "            if index == 5:\n",
    "                cv2.circle(image,(landmark[0],landmark[1]), 5, (0,255,255), -1)\n",
    "                \n",
    "            if index == 6:\n",
    "                cv2.circle(image,(landmark[0],landmark[1]), 5, (0,255,255), -1)\n",
    "                \n",
    "            if index == 7:\n",
    "                cv2.circle(image,(landmark[0],landmark[1]), 5, (0,255,255), -1)\n",
    "                \n",
    "            if index == 8:\n",
    "                cv2.circle(image,(landmark[0],landmark[1]), 5, (0,255,255), -1)\n",
    "                \n",
    "            if index == 9:\n",
    "                cv2.circle(image,(landmark[0],landmark[1]), 5, (0,255,255), -1)\n",
    "                \n",
    "            if index == 10:\n",
    "                cv2.circle(image,(landmark[0],landmark[1]), 5, (0,255,255), -1)\n",
    "            \n",
    "            if index == 11:\n",
    "                cv2.circle(image,(landmark[0],landmark[1]), 5, (0,255,255), -1)\n",
    "                \n",
    "            if index == 12:\n",
    "                cv2.circle(image,(landmark[0],landmark[1]), 5, (0,255,255), -1)\n",
    "                \n",
    "            if index == 13:\n",
    "                cv2.circle(image,(landmark[0],landmark[1]), 5, (0,255,255), -1)\n",
    "                \n",
    "            if index == 14:\n",
    "                cv2.circle(image,(landmark[0],landmark[1]), 5, (0,255,255), -1)\n",
    "                \n",
    "            if index == 15:\n",
    "                cv2.circle(image,(landmark[0],landmark[1]), 5, (0,255,255), -1)\n",
    "                \n",
    "            if index == 16:\n",
    "                cv2.circle(image,(landmark[0],landmark[1]), 5, (0,255,255), -1)\n",
    "                \n",
    "            if index == 17:\n",
    "                cv2.circle(image,(landmark[0],landmark[1]), 5, (0,255,255), -1)\n",
    "                \n",
    "            if index == 18:\n",
    "                cv2.circle(image,(landmark[0],landmark[1]), 5, (0,255,255), -1)\n",
    "                \n",
    "            if index == 19:\n",
    "                cv2.circle(image,(landmark[0],landmark[1]), 5, (0,255,255), -1)\n",
    "                \n",
    "            if index == 20:\n",
    "                cv2.circle(image,(landmark[0],landmark[1]), 5, (0,255,255), -1)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_landmark_lines(image, landmark_points):\n",
    "    if len(landmark_points) > 0:\n",
    "        # Palm\n",
    "        cv2.line(image, landmark_points[0], landmark_points[1], (255,255,255), 2)\n",
    "        cv2.line(image, landmark_points[0], landmark_points[5], (255,255,255), 2)\n",
    "        cv2.line(image, landmark_points[0], landmark_points[17], (255,255,255), 2)\n",
    "        cv2.line(image, landmark_points[5], landmark_points[9], (255,255,255), 2)\n",
    "        cv2.line(image, landmark_points[9], landmark_points[13], (255,255,255), 2)\n",
    "        cv2.line(image, landmark_points[13], landmark_points[17], (255,255,255), 2)\n",
    "\n",
    "        # Thumb\n",
    "        cv2.line(image, landmark_points[1], landmark_points[2], (255,255,255), 2)\n",
    "        cv2.line(image, landmark_points[2], landmark_points[3], (255,255,255), 2)\n",
    "        cv2.line(image, landmark_points[3], landmark_points[4], (255,255,255), 2)\n",
    "\n",
    "        # Index\n",
    "        cv2.line(image, landmark_points[5], landmark_points[6], (255,255,255), 2)\n",
    "        cv2.line(image, landmark_points[6], landmark_points[7], (255,255,255), 2)\n",
    "        cv2.line(image, landmark_points[7], landmark_points[8], (255,255,255), 2)\n",
    "\n",
    "        #Middle\n",
    "        cv2.line(image, landmark_points[9], landmark_points[10], (255,255,255), 2)\n",
    "        cv2.line(image, landmark_points[10], landmark_points[11], (255,255,255), 2)\n",
    "        cv2.line(image, landmark_points[11], landmark_points[12], (255,255,255), 2)\n",
    "\n",
    "        # Ring\n",
    "        cv2.line(image, landmark_points[13], landmark_points[14], (255,255,255), 2)\n",
    "        cv2.line(image, landmark_points[14], landmark_points[15], (255,255,255), 2)\n",
    "        cv2.line(image, landmark_points[15], landmark_points[16], (255,255,255), 2)\n",
    "\n",
    "        # Pinky\n",
    "        cv2.line(image, landmark_points[17], landmark_points[18], (255,255,255), 2)\n",
    "        cv2.line(image, landmark_points[18], landmark_points[19], (255,255,255), 2)\n",
    "        cv2.line(image, landmark_points[19], landmark_points[20], (255,255,255), 2)\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "    return image\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_keypoints(landmarks):\n",
    "    temp_landmark_list = copy.deepcopy(landmarks)\n",
    "\n",
    "    # Converting into local coordinates\n",
    "    x, y = 0,0\n",
    "    for index, landmark_point in enumerate(landmarks):\n",
    "        if index == 0:\n",
    "            x,y = landmark_point[0],landmark_point[1]\n",
    "        \n",
    "        temp_landmark_list[index][0] = temp_landmark_list[index][0] - x\n",
    "        temp_landmark_list[index][1] = temp_landmark_list[index][1] - y\n",
    "\n",
    "    # Converting into 1D  list\n",
    "    temp_landmark_list = list(itertools.chain.from_iterable(temp_landmark_list))\n",
    "\n",
    "    # Finding the max value for normalization \n",
    "    maximum = max(list(map(abs, temp_landmark_list)))\n",
    "    def normalization(n):\n",
    "        return n/maximum\n",
    "    temp_landmark_list = list(map(normalization, temp_landmark_list))\n",
    "    \n",
    "    return temp_landmark_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_mode(key, mode):\n",
    "    num = -1\n",
    "    # Setting labels 0-9\n",
    "    if 48 <= key <= 57:\n",
    "        num = key - 48\n",
    "    if key == 107:\n",
    "        mode = 1\n",
    "    return num, mode "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_logger(num, mode, pre_processed_keypoints):\n",
    "    if mode == 0:\n",
    "        pass\n",
    "    if mode == 1 and 0 <= num <= 9:\n",
    "        csv_path = \"/Users/Atharv/All scripts/SmartMAte/ASL Translation/model/keypoint_classifier/keypoints.csv\"\n",
    "        with open(csv_path, 'rb+') as f:\n",
    "            f.seek(-1, os.SEEK_END)\n",
    "            last_char = f.read(1)\n",
    "            if last_char != b'\\n':\n",
    "                f.write(b'\\n')\n",
    "        with open(csv_path, 'a', newline = \"\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([num, *pre_processed_keypoints])\n",
    "            print(\"mode = {%d}, label = {%d}\" %(mode, num))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "keypoint_classifier_labels = [\"Palm\", \"Peace\", \"Fist\", \"Ok / Good\", \"Fuck\", \"Rock\", \"Thumbs Up\", \"Thumbs Down\", \"Call\", \"Fingers Crossed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "vid = cv2.VideoCapture(0)\n",
    "keypoint_classifier = tf.keras.models.load_model(\"model/keypoint_classifier/keypoints_classifier.keras\")\n",
    "mode = 0\n",
    "while (True):\n",
    "\n",
    "    key = cv2.waitKey(10)\n",
    "\n",
    "    if key == 27:\n",
    "        break\n",
    "    num, mode = select_mode(key,mode)\n",
    "    # Camera capture\n",
    "    ret, image = vid.read()\n",
    "    # Stopping the loop camera stops detecting\n",
    "    if not ret:\n",
    "        break\n",
    "    # Flipping the image as the camera capture is mirrored.\n",
    "    image = cv2.flip(image,1)\n",
    "    debug_image = copy.deepcopy(image)\n",
    "    # Hand detection\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    results = hands.process(image)\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks, handedness in zip(results.multi_hand_landmarks, results.multi_handedness):\n",
    "            # Assigning bounding box\n",
    "            brect = calc_bounding_box(debug_image, hand_landmarks)\n",
    "            # Landmark calculation \n",
    "            landmarks = calc_landmark_points(debug_image, hand_landmarks)\n",
    "            # Localizing and Normalizing hand landmarks in the detected hand \n",
    "            pre_processed_keypoints = preprocess_keypoints(landmarks)\n",
    "            input_array = np.array(pre_processed_keypoints).reshape(1,-1)\n",
    "            # Inferencing from Keypoint classifier model \n",
    "            output = keypoint_classifier.predict(input_array, verbose = 0)\n",
    "            sign_id = np.argmax(np.squeeze(output))\n",
    "            sign = keypoint_classifier_labels[sign_id]\n",
    "            # Logging the points as needed \n",
    "            csv_logger(num, mode, pre_processed_keypoints)\n",
    "            # Drawing bounding box\n",
    "            debug_image = draw_bounding_box(debug_image, brect, sign, handedness)\n",
    "            debug_image = draw_landmark_points(debug_image, landmarks)\n",
    "            debug_image = draw_landmark_lines(debug_image, landmarks)\n",
    "\n",
    "    cv2.imshow('Hand Gesture Recognition', debug_image)\n",
    "    \n",
    "vid.release()\n",
    "cv2.destroyWindow('Hand Gesture Recognition')\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
